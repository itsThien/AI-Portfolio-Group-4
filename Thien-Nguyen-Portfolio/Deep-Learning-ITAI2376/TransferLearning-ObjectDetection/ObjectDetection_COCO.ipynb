{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection using Transfer Learning (PyTorch + COCO)\n",
    "\n",
    "This notebook demonstrates Faster R-CNN with ResNet-50 backbone pretrained on COCO, fine-tuned on COCO dataset."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "!pip install torch torchvision pycocotools matplotlib opencv-python tqdm"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.datasets import CocoDetection\n",
    "from torchvision.transforms import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download COCO Dataset (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "!mkdir -p coco\n",
    "!cd coco && wget http://images.cocodataset.org/zips/train2017.zip\n",
    "!cd coco && wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
    "!cd coco && unzip -q train2017.zip\n",
    "!cd coco && unzip -q annotations_trainval2017.zip"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Dataset paths\n",
    "root = \"coco/train2017\"\n",
    "annFile = \"coco/annotations/instances_train2017.json\"\n",
    "\n",
    "train_dataset = CocoDetection(root=root, annFile=annFile, transform=F.to_tensor)\n",
    "print(\"Dataset size:\", len(train_dataset))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=2, collate_fn=collate_fn)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Load pretrained Faster R-CNN\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
    "num_classes = 91  # COCO classes + background\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Training loop (short demo)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "num_epochs = 1\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    progress = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    for images, targets in progress:\n",
    "        images = [img.to(device) for img in images]\n",
    "        formatted_targets = []\n",
    "        for t, img in zip(targets, images):\n",
    "            boxes = []\n",
    "            labels = []\n",
    "            for obj in t:\n",
    "                boxes.append(obj['bbox'])\n",
    "                labels.append(obj['category_id'])\n",
    "            boxes = torch.as_tensor(boxes, dtype=torch.float32).reshape(-1, 4)\n",
    "            boxes[:, 2:] += boxes[:, :2]\n",
    "            labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "            formatted_targets.append({'boxes': boxes.to(device), 'labels': labels.to(device)})\n",
    "\n",
    "        loss_dict = model(images, formatted_targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "        progress.set_postfix(loss=losses.item())"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Inference on one sample\n",
    "model.eval()\n",
    "test_img = Image.open(train_dataset[0][0])\n",
    "with torch.no_grad():\n",
    "    prediction = model([F.to_tensor(test_img).to(device)])\n",
    "\n",
    "prediction"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def plot_detections(img, prediction, score_threshold=0.5):\n",
    "    img = np.array(img)\n",
    "    boxes = prediction[0]['boxes'].cpu().numpy()\n",
    "    scores = prediction[0]['scores'].cpu().numpy()\n",
    "    labels = prediction[0]['labels'].cpu().numpy()\n",
    "    \n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(img)\n",
    "    ax = plt.gca()\n",
    "    \n",
    "    for box, score, label in zip(boxes, scores, labels):\n",
    "        if score < score_threshold:\n",
    "            continue\n",
    "        x1, y1, x2, y2 = box.astype(int)\n",
    "        rect = plt.Rectangle((x1, y1), x2-x1, y2-y1, fill=False, color='lime', linewidth=2)\n",
    "        ax.add_patch(rect)\n",
    "        ax.text(x1, y1, f'{label}:{score:.2f}', color='yellow', fontsize=8, backgroundcolor='black')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "plot_detections(test_img, prediction)"
   ],
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
